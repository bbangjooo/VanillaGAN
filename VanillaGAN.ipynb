{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torch import nn,cuda,optim\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from os import path\n",
    "from google.colab import drive\n",
    "\n",
    "notebooks_dir_name = 'notebooks'\n",
    "drive.mount('/content/gdrive')\n",
    "notebooks_base_dir = path.join('./gdrive/My Drive/', notebooks_dir_name)\n",
    "if not path.exists(notebooks_base_dir):\n",
    "  print('Check your google drive directory. See you file explorer')\n",
    "# Settings\n",
    "download_root='mnist'\n",
    "stored_path='images'\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,),std=(0.5,))\n",
    "])\n",
    "device= 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "leraing_rate=0.0002\n",
    "# Dataset\n",
    "train_set=MNIST(download_root,train=True,transform=transform,download=True)\n",
    "\n",
    "# Dataloader\n",
    "train_loader=DataLoader(train_set,batch_size=60,shuffle=True)\n",
    "\n",
    "# Image_dir\n",
    "import os\n",
    "import imageio\n",
    "\n",
    "if not os.path.isdir(stored_path):\n",
    "    os.makedirs(stored_path,exist_ok=True)\n",
    "\n",
    "# Model\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        def gen_block(in_features,out_features):\n",
    "            layers=[nn.Linear(in_features,out_features)]\n",
    "            layers.append(nn.ReLU())\n",
    "            return layers\n",
    "        self.generator=nn.Sequential(\n",
    "            *gen_block(100,128),\n",
    "            *gen_block(128,256),\n",
    "            *gen_block(256,512),\n",
    "            *gen_block(512,1024),\n",
    "            nn.Linear(1024,784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x=self.generator(x)\n",
    "        x=torch.view(x.size(0),-1)\n",
    "        return x\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        def disc_block(in_features,out_features):\n",
    "            layers=[nn.Linear(in_features,out_features)]\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout())\n",
    "            return layers\n",
    "        self.discriminator=nn.Sequential(\n",
    "            *disc_block(784,1024),\n",
    "            *disc_block(1024,512),\n",
    "            *disc_block(512,256),\n",
    "            nn.Linear(256,1),\n",
    "            nn.Sigmoid()   \n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x=torch.view(x.size(0),-1)\n",
    "        x=self.discriminator(x)\n",
    "        return x\n",
    "\n",
    "Gen=Generator().to(device)\n",
    "Discrim=Discriminator().to(device)\n",
    "\n",
    "# Loss & Optim\n",
    "criterion=nn.BCELoss()\n",
    "\n",
    "G_optimizer=optim.Adam(Gen.parameters(),lr=leraing_rate, betas=(0.5, 0.999))\n",
    "D_optimizer=optim.Adam(Discrim.parameters(),lr=leraing_rate, betas=(0.5, 0.999))\n",
    "\n",
    "# Train\n",
    "def train(epoch):\n",
    "    for batch_idx,(data,_) in enumerate(train_loader):\n",
    "        batch_size=data.size(0)\n",
    "        fake_correct=Variable(torch.zeros(batch_size,1)).to(device)\n",
    "        real_correct=Variable(torch.ones(batch_size,1)).to(device)\n",
    "        z=Variable(torch.randn((batch_size, 100))).to(device)\n",
    "        data=Variable(data).to(device)\n",
    "\n",
    "        # Gen 학습\n",
    "        gen_img=Gen(z)\n",
    "        G_optimizer.zero_grad()\n",
    "        G_loss=criterion(Discrim(gen_img),real_correct)\n",
    "        G_loss.backward()\n",
    "        G_optimizer.step()\n",
    "        # Discrim 학습\n",
    "        # 진짜 이미지를 진짜로 판별할 수 있게 학습\n",
    "        real_output=Discrim(data)\n",
    "        D_real_loss=criterion(real_output,real_correct)\n",
    "\n",
    "        # 가짜 이미지를 가짜로 판별할 수 있게 학습\n",
    "        z=Variable(torch.randn((batch_size, 100))).to(device)\n",
    "        fake_image=Gen(z)\n",
    "        fake_output=Discrim(fake_image)\n",
    "        D_optimizer.zero_grad()\n",
    "        D_fake_loss=criterion(fake_output,fake_correct)\n",
    "        D_loss=(D_real_loss+D_fake_loss)/2\n",
    "        D_loss.backward()\n",
    "        D_optimizer.step()\n",
    "\n",
    "        batch_finish=epoch * len(train_loader) + batch_idx\n",
    "        if (batch_finish) % 400 == 0:\n",
    "            print(\"[Epoch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "            % (epoch, 200, D_loss.item(), G_loss.item())\n",
    "            )\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        gen_img = gen_img.reshape([batch_size, 1, 28, 28])\n",
    "        img_grid = make_grid(gen_img, nrow=10, normalize=True)\n",
    "        save_image(img_grid, \"images/result_%d.png\"%(epoch+1)) \n",
    "if __name__ == \"__main__\":\n",
    "    for epoch in range(200):\n",
    "        train(epoch)\n",
    "    images=[]\n",
    "    for file_name in os.listdir(stored_path):\n",
    "        images.append(imageio.imread(file_name))\n",
    "        imageio.mimsave('result.gif',images)"
   ]
  }
 ]
}